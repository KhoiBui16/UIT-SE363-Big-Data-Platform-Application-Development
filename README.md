# üõ°Ô∏è TikTok Safety Platform - Big Data Harmful Content Detection System

<div align="center">

**üìö Course**: SE363 - Big Data Platform Application Development  
**üèõÔ∏è Institution**: University of Information Technology (UIT) - VNU-HCM  
**üë• Authors**: [KhoiBui16](https://github.com/KhoiBui16) ‚Ä¢ [BinhAnndapoet](https://github.com/BinhAnndapoet) ‚Ä¢ [PhamQuocNam](https://github.com/PhamQuocNam)

---

![TikTok Safety](https://img.shields.io/badge/TikTok-Safety-ff0050?style=for-the-badge&logo=tiktok&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Apache Spark](https://img.shields.io/badge/Apache-Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/Apache-Kafka-231F20?style=for-the-badge&logo=apachekafka&logoColor=white)

**A Big Data platform for detecting harmful content on TikTok using multimodal AI (Text + Video + Fusion)**

</div>

---

## üìã Project Overview

This project implements a **Lambda Architecture** based Big Data platform for real-time detection of harmful content on TikTok videos. The system combines:

- **Batch Processing**: Training multimodal AI models (Text, Video, Fusion)
- **Stream Processing**: Real-time video analysis using Apache Spark Streaming
- **Serving Layer**: Streamlit Dashboard for monitoring and content moderation

### Key Capabilities

- üîç **Multimodal Analysis**: Combines text (captions, comments) and video frame analysis
- ‚ö° **Real-time Processing**: Stream processing with Kafka + Spark
- ü§ñ **AI-Powered Detection**: State-of-the-art models for content classification
- üìä **Interactive Dashboard**: Real-time monitoring and content audit tools
- üîÑ **MLflow Integration**: Model versioning and auto-update capabilities

---

## üìë Table of Contents

1. [Quick Start](#-quick-start)
2. [Project Structure](#-project-structure)
3. [Architecture](#Ô∏è-architecture)
4. [Layer Architecture](#-layer-architecture)
5. [Airflow DAGs](#-airflow-dags)
6. [Data Flow](#-data-flow)
7. [Features](#-features)
8. [AI Models](#-ai-models)
9. [Data Crawling](#-data-crawling)
10. [Model Training](#-model-training)
11. [Installation Guide](#-installation-guide)
12. [Usage](#-usage)
13. [Testing](#-testing)
14. [Documentation](#-documentation)
15. [Troubleshooting](#-troubleshooting)
16. [Tech Stack](#Ô∏è-tech-stack)
17. [Authors](#-authors)

---


## üöÄ Quick Start & Installation Guide

### Prerequisites

| Requirement | Minimum | Recommended |
|-------------|---------|-------------|
| **OS** | Ubuntu 20.04+ / Windows 10+ (WSL2) | Ubuntu 22.04 |
| **Docker** | Docker Engine 20.10+ & Compose v2 | Latest |
| **Python** | 3.9+ | 3.10+ |
| **RAM** | 16GB | 32GB |
| **Storage** | 50GB free | 100GB+ |

### Step 1: Clone Repository

```bash
git clone https://github.com/BinhAnndapoet/UIT-SE363-Big-Data-Platform-Application-Development.git
cd UIT-SE363-Big-Data-Platform-Application-Development
```

### Step 2: Setup Environment

```bash
# Copy environment template
cp streaming/.env.example streaming/.env

# (Optional) Create Python virtual environment
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .\.venv\Scripts\Activate.ps1  # Windows PowerShell

# Install dependencies (for local development)
pip install -r requirements.txt
```

### Step 3: Setup Cookies (Required for Crawling)

1. Install Chrome extension **"Get cookies.txt LOCALLY"**
2. Login to TikTok in Chrome
3. Click extension ‚Üí **"Export All Cookies"** ‚Üí Save as `cookies.txt`
4. Copy to streaming folder:
   ```bash
   cp cookies.txt streaming/ingestion/cookies.txt
   ```

### Step 4: Download Data (Optional)

> **üí° Alternative**: Skip this step - the streaming pipeline will automatically crawl new videos!

| Folder | Download Link | Description |
|--------|---------------|-------------|
| `data/` | [Google Drive](https://drive.google.com) *(link TBD)* | Raw crawled videos (batch 1) |
| `data_1/` | [Google Drive](https://drive.google.com) *(link TBD)* | Raw crawled videos (batch 2) |
| `data_viet/` | [Google Drive](https://drive.google.com) *(link TBD)* | Vietnamese TikTok videos |

### Step 5: Run with Docker

```bash
cd streaming
chmod +x start_all.sh
./start_all.sh
```

**Alternative Docker Commands:**
```bash
# Manual start
docker compose up -d --build

# Check status
docker compose ps

# View logs
docker compose logs -f spark-processor

# Stop all
docker compose down
```

### Access Services

| Service | URL | Credentials |
|---------|-----|-------------|
| **Dashboard** | http://localhost:8501 | - |
| **Airflow** | http://localhost:8089 | admin / admin |
| **MLflow** | http://localhost:5000 | - |
| **MinIO Console** | http://localhost:9001 | admin / password123 |
| **Spark Master** | http://localhost:9090 | - |

---

## üéÆ Usage

### Running the Pipeline

1. **Open Airflow** at http://localhost:8089 (login: admin/admin)

2. **Trigger DAG 1**: `1_TIKTOK_ETL_COLLECTOR`
   - Crawls TikTok videos by hashtags
   - Wait for completion (Success status)

3. **Trigger DAG 2**: `2_TIKTOK_STREAMING_PIPELINE`
   - Downloads videos to MinIO
   - Runs AI inference with Spark
   - Stores results in PostgreSQL
   - **Auto-loops** for continuous processing

4. **Trigger DAG 3**: `3_MODEL_RETRAINING` (Optional/Scheduled)
   - Checks for new data and performance drift
   - Retrains models on Spark Cluster
   - Registers new best models to MLflow (auto-updates pipeline)

5. **Monitor Dashboard** at http://localhost:8501

---

## üß™ Testing

### Shell Scripts (Ubuntu)

```bash
cd streaming

# Run all tests
./tests/run_all_tests.sh

# Test individual layers
./tests/test_layer1_infrastructure.sh  # Docker, Kafka, MinIO
./tests/test_layer2_ingestion.sh       # Crawler, Downloader
./tests/test_layer3_processing.sh      # Spark, AI Models
./tests/test_layer4_dashboard.sh       # Streamlit Dashboard
```

### Python Tests

```bash
cd streaming
pytest tests/ -v
```

---

## üìÅ Project Structure

```bash
UIT-SE363-Big-Data-Platform-Application-Development/
‚îú‚îÄ‚îÄ streaming/                          # üöÄ Real-time Pipeline Root
‚îÇ   ‚îú‚îÄ‚îÄ airflow/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dags/                       # ‚ö° Airflow DAGs
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ 1_TIKTOK_ETL_COLLECTOR.py
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ 2_TIKTOK_STREAMING_PIPELINE.py
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ 3_MODEL_RETRAINING.py
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/                      # üì• Data Ingestion Layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clients/                    # External clients
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ minio_kafka_clients.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ crawler.py                  # TikTok crawler (Selenium)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ downloader.py               # Video downloader
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main_worker.py              # Main ingestion worker
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ processing/                     # üß† Stream Processing Layer
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ spark_processor.py          # Spark AI Inference Job
‚îÇ   ‚îú‚îÄ‚îÄ mlflow/                         # üîÑ MLOps & Model Registry
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ client.py                   # Registry client wrapper
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_updater.py            # Model auto-updater logic
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/                      # üìä Streamlit Dashboard
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py                      # Main dashboard entrypoint
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ helpers.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ styles.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page_modules/               # UI Components
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile.dashboard
‚îÇ   ‚îú‚îÄ‚îÄ spark/                          # üê≥ Spark Docker Config
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ tests/                          # üß™ Comprehensive Test Suite
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run_all_tests.sh            # Master test script
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_layer1_infrastructure.sh
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_layer2_ingestion.sh
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_layer3_processing.sh
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_layer4_dashboard.sh
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_layer5_mlflow.sh
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_mlflow.py              # Unit tests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_dashboard.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_db_layer.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ... (helper scripts)
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml              # Main Infrastructure Config
‚îÇ   ‚îú‚îÄ‚îÄ start_all.sh                    # One-click Startup Script
‚îÇ   ‚îú‚îÄ‚îÄ link_host.sh                    # Host URL generator
‚îÇ   ‚îî‚îÄ‚îÄ .env                            # Environment Config
‚îÇ
‚îú‚îÄ‚îÄ train_eval_module/                  # ü§ñ AI Model Training & Eval
‚îÇ   ‚îú‚îÄ‚îÄ text/                           # Text Model (CafeBERT)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/                        # Model source code
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ text_configs.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ output/uitnlp_CafeBERT/     # Spec: 1024-dim
‚îÇ   ‚îú‚îÄ‚îÄ video/                          # Video Model (VideoMAE)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ video_configs.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ output/MCG-NJU_videomae.../ # Spec: 768-dim
‚îÇ   ‚îú‚îÄ‚îÄ fusion/                         # Multimodal Fusion
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fusion_configs.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ output/fusion_videomae/     # Retrained 1024-dim Text + 768-dim Video
‚îÇ   ‚îú‚îÄ‚îÄ audio/                          # Audio Model (Experimental)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îú‚îÄ‚îÄ scripts/                        # Utility Scripts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ push_hf_model.py            # HuggingFace Uploader
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ split_data.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ check_paths.py
‚îÇ   ‚îî‚îÄ‚îÄ shared_utils/                   # Common Utilities
‚îÇ       ‚îú‚îÄ‚îÄ file_utils.py
‚îÇ       ‚îú‚îÄ‚îÄ logger.py
‚îÇ       ‚îú‚îÄ‚îÄ mlflow_logger.py
‚îÇ       ‚îî‚îÄ‚îÄ processing.py
‚îÇ
‚îú‚îÄ‚îÄ crawl_scripts/                      # üï∑Ô∏è Standalone Crawling Utils
‚îÇ   ‚îú‚îÄ‚îÄ ScrapingVideoTiktok.py          # Main video scraper
‚îÇ   ‚îú‚îÄ‚îÄ find_tiktok_links.py            # Link finder by hashtag
‚îÇ   ‚îú‚îÄ‚îÄ create_sub_samples_tiktok_links.py
‚îÇ   ‚îú‚îÄ‚îÄ crawl_tiktok_links_update_v1.py
‚îÇ   ‚îî‚îÄ‚îÄ crawl_tiktok_links_update_viet.py
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                          # üìì Analysis & Experiments
‚îÇ   ‚îú‚îÄ‚îÄ ScrapingVideoTiktok.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ create_sub_samples_tiktok_links.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ eda.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ audio_trial.ipynb
‚îÇ
‚îú‚îÄ‚îÄ docs/                               # üìö Project Documentation
‚îÇ   ‚îú‚îÄ‚îÄ streaming/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_PROJECT_OVERVIEW.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_LAYER_ARCHITECTURE.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_DASHBOARD_PAGES.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 04_SETUP_GUIDE.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 05_TESTING_GUIDE.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 06_API_REFERENCE.md
‚îÇ   ‚îî‚îÄ‚îÄ mlflow/
‚îÇ       ‚îî‚îÄ‚îÄ MLFLOW_INTEGRATION_GUIDE.md
‚îÇ
‚îú‚îÄ‚îÄ processed_data/                     # üíæ Processed Datasets (CSV)
‚îú‚îÄ‚îÄ data/                               # üì¶ Raw Data Storage (Images/Videos)
‚îî‚îÄ‚îÄ requirements.txt                    # üêç Project Dependencies (Root)
```

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        LAMBDA ARCHITECTURE                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   TikTok     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Crawler    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   MinIO (Storage)    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   Videos     ‚îÇ    ‚îÇ   Service    ‚îÇ    ‚îÇ   Videos & Audios    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                             ‚îÇ                        ‚îÇ               ‚îÇ
‚îÇ                             ‚ñº                        ‚ñº               ‚îÇ
‚îÇ                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ                      ‚îÇ    Kafka     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Spark Streaming    ‚îÇ   ‚îÇ
‚îÇ                      ‚îÇ   Broker     ‚îÇ    ‚îÇ   (AI Inference)     ‚îÇ   ‚îÇ
‚îÇ                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                      ‚îÇ               ‚îÇ
‚îÇ                                                      ‚ñº               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   Streamlit  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ  PostgreSQL  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ   Processed Results  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   Dashboard  ‚îÇ    ‚îÇ   Database   ‚îÇ    ‚îÇ                      ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Docker Services

| Service | Port | Description |
|---------|------|-------------|
| **Dashboard** | `8501` | Streamlit monitoring UI |
| **Airflow** | `8080` | DAG scheduling & orchestration |
| **Spark Master** | `9090` | Spark cluster management |
| **Spark Processor** | - | AI inference streaming job |
| **Kafka** | `9092` | Message broker |
| **MinIO** | `9000`, `9001` | Object storage (videos/audios) |
| **PostgreSQL** | `5432` | Results database |
| **MLflow** | `5000` | Model registry & tracking |

---

## üèóÔ∏è Layer Architecture

The system follows a **9-layer architecture**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Layer 9: MODEL REGISTRY        ‚îÇ  MLflow (port 5000)                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Layer 8: PRESENTATION          ‚îÇ  Streamlit Dashboard (port 8501)    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Layer 7: DATA STORAGE          ‚îÇ  PostgreSQL (processed_results)     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Layer 6: ORCHESTRATION         ‚îÇ  Airflow DAGs (port 8080)           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Layer 5: STREAM PROCESSING     ‚îÇ  Spark Streaming + AI Models        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Layer 4: DATA INGESTION        ‚îÇ  Crawler ‚Üí Downloader ‚Üí Producer    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Layer 3: OBJECT STORAGE        ‚îÇ  MinIO (videos, audios)             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Layer 2: MESSAGE QUEUE         ‚îÇ  Kafka + Zookeeper                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  Layer 1: INFRASTRUCTURE        ‚îÇ  Docker Network, Volumes            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Layer Details

| Layer | Components | Key Files |
|-------|------------|-----------|
| **L1: Infrastructure** | Docker Network, Volumes | [docker-compose.yml](streaming/docker-compose.yml) |
| **L2: Message Queue** | Kafka (9092), Zookeeper | [docker-compose.yml](streaming/docker-compose.yml) |
| **L3: Object Storage** | MinIO (9000/9001) | [minio_kafka_clients.py](streaming/ingestion/clients/minio_kafka_clients.py) |
| **L4: Data Ingestion** | Crawler, Downloader, Producer | [crawler.py](streaming/ingestion/crawler.py), [main_worker.py](streaming/ingestion/main_worker.py) |
| **L5: Stream Processing** | Spark + AI Models | [spark_processor.py](streaming/processing/spark_processor.py) |
| **L6: Orchestration** | Airflow DAGs | [airflow/dags/](streaming/airflow/dags/) |
| **L7: Data Storage** | PostgreSQL | [docker-compose.yml](streaming/docker-compose.yml), [infra/postgres/](streaming/infra/postgres/) |
| **L8: Presentation** | Streamlit Dashboard | [dashboard/app.py](streaming/dashboard/app.py) |
| **L9: Model Registry** | MLflow Server | [mlflow/client.py](streaming/mlflow/client.py), [model_updater.py](streaming/mlflow/model_updater.py) |

### MLflow Layer (L9) - Model Registry & Auto-Update

**Purpose**: Automatic model versioning, tracking, and production updates based on F1-score.

**Features:**
- üìä **Experiment Tracking**: Log metrics, params, artifacts for each training run
- üì¶ **Model Registry**: Version control for text, video, and fusion models
- üîÑ **Auto-Update**: Every **2 minutes (testing)** or **30 minutes (default)**, Spark checks for better models in MLflow
- üìà **F1-Score Based**: Only updates if new model surpasses threshold:

| Model | Minimum F1 Threshold |
|-------|---------------------|
| Text | 0.75 |
| Video | 0.70 |
| Fusion | 0.80 |

**How it works:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Training Job   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  MLflow Server  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ Spark Processor ‚îÇ
‚îÇ (logs metrics)  ‚îÇ     ‚îÇ  (port 5000)    ‚îÇ     ‚îÇ (checks every   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  2 or 30 minutes)‚îÇ
                               ‚îÇ                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚ñº
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ If new F1 > current ‚îÇ
                     ‚îÇ ‚Üí Download & Update ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÑ Airflow DAGs

### DAG 1: `1_TIKTOK_ETL_COLLECTOR`

**Purpose**: Crawl TikTok videos by hashtags

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ monitor_db_health   ‚îÇ ‚îÄ‚îÄ‚îÄ‚ñ∫ ‚îÇ   crawl_tiktok_links   ‚îÇ
‚îÇ (pg_isready check)  ‚îÇ      ‚îÇ  (Selenium + Xvfb)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

| Task | Description | Timeout |
|------|-------------|---------|
| `monitor_db_health` | Check PostgreSQL connection | - |
| `crawl_tiktok_links` | Crawl TikTok with Selenium (headless) | 45 min |

### DAG 2: `2_TIKTOK_STREAMING_PIPELINE`

**Purpose**: Download videos, run AI inference, continuous processing loop

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ prepare_environ  ‚îÇ‚îÄ‚îÄ‚ñ∫‚îÇ check_kafka_infra‚îÇ‚îÄ‚îÄ‚ñ∫‚îÇ run_ingestion_worker‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                        ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ verify_spark_result‚îÇ‚îÄ‚îÄ‚ñ∫‚îÇ wait_30s_cooldown‚îÇ‚îÄ‚îÄ‚ñ∫‚îÇ loop_self_trigger‚îÇ
‚îÇ   (SQL Sensor)     ‚îÇ   ‚îÇ                 ‚îÇ   ‚îÇ  (Auto-restart)  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

| Task | Description |
|------|-------------|
| `prepare_environment` | Check queue file exists |
| `check_kafka_infra` | Verify Kafka is healthy |
| `run_ingestion_worker` | Download ‚Üí Upload MinIO ‚Üí Send Kafka |
| `verify_spark_ai_result` | Wait for Spark processing |
| `wait_30s_cooldown` | Cooldown before next loop |
| `loop_self_trigger` | Self-trigger for continuous processing |

### DAG 3: `3_MODEL_RETRAINING`

**Purpose**: Automated model retraining & MLflow registration

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ check_new_data ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ submit_spark_job ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ monitor_spark_job ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ notify_success ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ  (REST API)      ‚îÇ     ‚îÇ  (Polling)        ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

| Task | Description |
|------|-------------|
| `check_new_data` | Validate if sufficient new data exists |
| `submit_training_job` | Submit training job to Spark Master (Cluster Mode) |
| `monitor_training_job` | Track job status until FINISHED |
| `notify_success` | Log completion and registration status |

---

## üìä Data Flow

```
     TikTok Website
          ‚îÇ
          ‚ñº (1. Crawl)
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Crawler   ‚îÇ ‚îÄ‚îÄ‚îÄ‚ñ∫ tiktok_links_viet.csv
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚ñº (2. Download)
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Downloader ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  MinIO  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚ñº (3. Produce)
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Producer  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ  Kafka  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚ñº (4. AI Inference)
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ         Spark Processor         ‚îÇ
    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
    ‚îÇ  ‚îÇ Text ‚îÇ ‚îÇVideo ‚îÇ ‚îÇFusion‚îÇ    ‚îÇ
    ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚ñº (5. Store)
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  PostgreSQL ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ
          ‚ñº (6. Display)
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Dashboard  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚ú® Features

### 1. Analytics Dashboard
- **KPI Monitoring**: Total processed videos, harmful detection rate, average risk score
- **Visual Analysis**: Time-series charts and category distribution
- **Real-time Updates**: Live data refresh from PostgreSQL

### 2. System Operations
- **Pipeline Control**: Start/Stop crawler and streaming pipelines
- **Status Monitor**: Real-time container and service health checks
- **System Logs**: Centralized logging viewer

### 3. Content Audit
- **Gallery Mode**: Visual grid of processed videos with risk scores
- **Detail View**: In-depth analysis of individual videos
- **Table View**: Sortable/filterable data table

### 4. Database Manager
- **Table Browser**: Schema inspection and data preview
- **Query Tool**: Execute custom SQL queries
- **Statistics**: Database performance metrics

### 5. Project Info
- **Architecture Diagrams**: Visual system documentation
- **Data Pipeline Flow**: End-to-end data journey
- **AI Models Documentation**: Model specifications

---

## ü§ñ AI Models

All models are available on HuggingFace Hub:

### Text Classification Model
**Repository**: [KhoiBui/tiktok-text-safety-classifier](https://huggingface.co/KhoiBui/tiktok-text-safety-classifier)

- **Base Model**: CafeBERT (uitnlp/CafeBERT)
- **Task**: Binary classification (safe/harmful)
- **Languages**: Vietnamese, English

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained("KhoiBui/tiktok-text-safety-classifier")
model = AutoModelForSequenceClassification.from_pretrained("KhoiBui/tiktok-text-safety-classifier")
```

### Video Classification Model
**Repository**: [KhoiBui/tiktok-video-safety-classifier](https://huggingface.co/KhoiBui/tiktok-video-safety-classifier)

- **Base Model**: VideoMAE (MCG-NJU/videomae-base-finetuned-kinetics)
- **Task**: Binary classification (safe/harmful)
- **Input**: 16 video frames (224x224)

### Multimodal Fusion Model
**Repository**: [KhoiBui/tiktok-multimodal-fusion-classifier](https://huggingface.co/KhoiBui/tiktok-multimodal-fusion-classifier)

- **Architecture**: Late Fusion with Cross-Attention + Gating
- **Text Backbone**: KhoiBui/tiktok-text-safety-classifier (1024-dim XLM-RoBERTa compatible)
- **Video Backbone**: KhoiBui/tiktok-video-safety-classifier (768-dim VideoMAE)
- **Internal Weights**: 50% text + 50% video (trong Cross-Attention)
- **Status**: **Retrained & Fixed** (Jan 29, 2026) to resolve dimension mismatch (1024 vs 768).

### Inference Modes (Streaming Pipeline)

Spark Processor s·ª≠ d·ª•ng chi·∫øn l∆∞·ª£c **auto-fallback** trong `spark_processor.py`:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Step 1: Th·ª≠ load FUSION MODEL                              ‚îÇ
‚îÇ    ‚úì Th√†nh c√¥ng ‚Üí D√πng FUSION mode (50-50 trained weights)  ‚îÇ
‚îÇ    ‚úó Th·∫•t b·∫°i  ‚Üí Auto-fallback v·ªÅ LATE_SCORE                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

| Mode | Khi n√†o d√πng | Models Used | Score Calculation |
|------|--------------|-------------|-------------------|
| **FUSION** | Default (n·∫øu load ƒë∆∞·ª£c) | 1 Fusion model | End-to-end (50-50 trained) |
| **LATE_SCORE** | Fallback (khi FUSION fail) | 2 separate models | `text*0.3 + video*0.7` |

> **‚ö†Ô∏è Note**: FUSION is the primary mode with end-to-end trained model. LATE_SCORE is only used automatically when Fusion model fails to load.

### Rule-based Filtering (Pre-AI Check)

Before calling AI models, the system performs a quick check based on **60+ banned keywords** in Vietnamese, divided into 5 groups:

| Group | Content Type | Examples |
|-------|--------------|----------|
| 1 | Adult/Sexual content | 18+, sex, xxx |
| 2 | Violence/Gang-related | fighting, knife, gun |
| 3 | Gambling/Fraud | casino, betting, ponzi |
| 4 | Social vices | drugs, narcotics |
| 5 | Superstition | fortune telling, black magic |

**Logic**: If text contains banned keyword ‚Üí Immediately assign `score = 0.85` + `label = harmful` **WITHOUT calling AI** ‚Üí Saves GPU resources.

### Streaming Inference Logic

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. Kafka Consumer reads messages (max 5 offsets/trigger)      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  2. Download video from MinIO ‚Üí Extract 16 frames (decord)     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  3. Rule-based check (60+ keywords)                            ‚îÇ
‚îÇ     ‚úì Match ‚Üí score=0.85, skip AI                              ‚îÇ
‚îÇ     ‚úó No match ‚Üí Continue to AI                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  4. AI Inference (UDFs - Lazy Loading)                         ‚îÇ
‚îÇ     - Text UDF: CafeBERT (max 256 tokens)                      ‚îÇ
‚îÇ     - Video UDF: VideoMAE (16 frames 224x224)                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  5. Score Fusion: text*0.3 + video*0.7 (configurable)          ‚îÇ
‚îÇ     - Threshold = 0.5 ‚Üí final_decision                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  6. PostgreSQL UPSERT (10 columns + processed_at)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìä Dataset Statistics

### Data Sources

| Folder | Videos | Description |
|--------|--------|-------------|
| `data/` | 959 | Original dataset (mixed languages) |
| `data_1/` | 838 | Supplementary dataset |
| `data_viet/` | 818 | Vietnamese-only dataset |
| **Total Collected** | **2,615** | - |
| **After Filtering** | **1,820** | Removed corrupt/short/no-text videos |

### Train/Val/Test Split (80:10:10)

| Split | Samples | Safe | Harmful |
|-------|---------|------|---------|
| Train | 1,456 | ~1,100 | ~356 |
| Val | 182 | 137 | 45 |
| Test | 182 | 137 | 45 |

> **Note**: Video test set = 180 samples (2 videos corrupt/too short for VideoMAE)

---

## üìà Experimental Results

### Text Models (Test Set = 182 samples)

| Model | Accuracy | F1-Harmful | Precision | Recall |
|-------|----------|------------|-----------|--------|
| **CafeBERT** | **79.7%** | **57.5%** | 59.5% | 55.6% |
| XLM-RoBERTa | 75.8% | 38.9% | 50.0% | 31.8% |
| DistilBERT | 70.3% | 46.0% | 48.6% | 43.7% |

### Video Models (Test Set = 180 samples)

| Model | Accuracy | F1-Harmful | Precision | Recall |
|-------|----------|------------|-----------|--------|
| **VideoMAE** | **87.2%** | **87.8%** | 88.5% | 87.1% |
| TimeSformer | 85.6% | 86.9% | 87.2% | 86.6% |
| ViViT | 78.3% | 81.2% | 79.4% | 83.1% |

### Fusion Model (Test Set = 182 samples)

| Metrics | Value |
|---------|-------|
| Accuracy | 79.1% |
| F1-Weighted | 79.4% |
| F1-Harmful | 60.0% |
| Precision-Harmful | 57.0% |
| Recall-Harmful | 62.2% |

**Confusion Matrix:**
```
                    Predicted
                 Safe    Harmful
Actual Safe       116       21
Actual Harmful     17       28
```

---

## ‚ö° Performance Metrics

| Metric | Value |
|--------|-------|
| **Throughput** | 1.66 videos/sec |
| **Hourly Capacity** | ~6,000 videos/hour |
| **Latency** | < 2 seconds per video |
| **Frame Extraction** | 0.2 sec/video |
| **VideoMAE Inference** | 0.4 sec/video |
| **DB Write** | 0.05 sec/batch |

> Tested on: 32GB RAM, GPU with 4GB+ VRAM

---

## üï∑Ô∏è Data Crawling

### Using Crawl Scripts (Local)

The `crawl_scripts/` folder contains scripts for collecting TikTok data:

```bash
cd crawl_scripts

# 1. Prepare cookies.txt (required for authentication)
# Export cookies from Chrome using "Get cookies.txt LOCALLY" extension
# Save as cookies.txt in crawl_scripts/

# 2. Find TikTok video links by hashtags
python find_tiktok_links.py --hashtag "funny" --max_videos 100

# 3. Download videos from collected links
python ScrapingVideoTiktok.py
```

### Using Airflow DAGs (Streaming Pipeline)

```bash
# 1. Start the streaming infrastructure
cd streaming
./start_all.sh

# 2. Access Airflow at http://localhost:8089 (admin/admin)

# 3. Trigger DAG "1_TIKTOK_ETL_COLLECTOR"
#    - Crawls TikTok videos by hashtags
#    - Saves links to CSV file

# 4. Trigger DAG "2_TIKTOK_STREAMING_PIPELINE"
#    - Downloads videos to MinIO
#    - Sends to Kafka for processing
```

### Data Output Structure

```
data/
‚îú‚îÄ‚îÄ crawl/
‚îÇ   ‚îî‚îÄ‚îÄ tiktok_links_viet.csv    # Crawled video URLs
‚îú‚îÄ‚îÄ videos/
‚îÇ   ‚îî‚îÄ‚îÄ {video_id}.mp4           # Downloaded videos
‚îî‚îÄ‚îÄ audios/
  ‚îî‚îÄ‚îÄ {video_id}.wav           # Extracted audio (optional)
```

---

## üèãÔ∏è Model Training

> For detailed training instructions, see [train_eval_module/README.md](train_eval_module/README.md)

### Prerequisites

```bash
cd train_eval_module

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Data Preparation (Required Before Training)

> ‚ö†Ô∏è **IMPORTANT**: After crawling data, you MUST run these scripts to prepare train/val/test splits before training any model.

**Step 1: Check System Paths & Data Status**

```bash
cd train_eval_module

# Verify all paths and check if data files exist
python scripts/check_paths.py
```

This script checks:
- Raw video folders (harmful/not_harmful)
- Audio processed directory
- Text labels CSV
- Master Index JSON files (train/val/test)

**Step 2: Create Train/Val/Test Splits**

```bash
# Generate data splits (80% train, 10% val, 10% test)
python scripts/split_data.py
```

This script creates:
- `data_splits/master_train.json`, `master_val.json`, `master_test.json` (Video/Audio)
- `processed_data/text/train_split.csv`, `val_split.csv`, `test_split.csv` (Text)
- `processed_data/fusion/train_fusion.json`, `val_fusion.json`, `test_fusion.json` (Fusion)

**Step 3: Verify Splits**

```bash
# Re-run check to confirm all split files are ready
python scripts/check_paths.py
```

Expected output: `üü¢ D·ªØ li·ªáu Index ƒê√É S·∫¥N S√ÄNG.`

### Train Text Model

```bash
# Train CafeBERT (Vietnamese - recommended)
python -m text.train --model_idx 0 --metric_type eval_f1

# Train XLM-RoBERTa (Multilingual)
python -m text.train --model_idx 1 --metric_type eval_f1
```

| Model | Index | Best For |
|-------|-------|----------|
| uitnlp/CafeBERT | 0 | Vietnamese text |
| xlm-roberta-base | 1 | Mixed languages |
| distilbert-base-multilingual-cased | 2 | Lighter/faster |

### Train Video Model

```bash
# Train VideoMAE (recommended)
python -m video.train --model_idx 0

# Train TimeSformer
python -m video.train --model_idx 1
```

### Train Fusion Model

> ‚ö†Ô∏è Requires pre-trained text and video models

```bash
# Train Late Fusion (text + video)
python -m fusion.train
```

### Push to HuggingFace Hub

```bash
huggingface-cli login

python scripts/push_hf_model.py \
    --model_path text/output/uitnlp_CafeBERT/train/best_checkpoint \
  --repo-id your-username/tiktok-text-safety-classifier
```

---

## üìñ Documentation

| Document | Description |
|----------|-------------|
| [01_PROJECT_OVERVIEW.md](docs/streaming/01_PROJECT_OVERVIEW.md) | Project introduction |
| [02_LAYER_ARCHITECTURE.md](docs/streaming/02_LAYER_ARCHITECTURE.md) | Architecture details |
| [03_DASHBOARD_PAGES.md](docs/streaming/03_DASHBOARD_PAGES.md) | Dashboard usage guide |
| [04_SETUP_GUIDE.md](docs/streaming/04_SETUP_GUIDE.md) | Installation guide |
| [05_TESTING_GUIDE.md](docs/streaming/05_TESTING_GUIDE.md) | Testing documentation |
| [MLFLOW_INTEGRATION_GUIDE.md](docs/mlflow/MLFLOW_INTEGRATION_GUIDE.md) | MLflow setup |

---

## üîß Troubleshooting

### Common Issues

**1. Port conflicts (8080, 8501, 5000, etc.):**
```bash
# Check which ports are in use
cd streaming
./scripts/check_ports.sh

# Kill specific port (example port 8080)
lsof -ti:8080 | xargs kill -9

# Or stop all Docker containers
docker compose down
```

**2. Airflow DAGs not showing up:**
```bash
# Wait 60s after starting for DAG parsing
# Or check Airflow scheduler logs
docker logs airflow-scheduler -f

# Manually trigger DAG list refresh
docker exec airflow-webserver airflow dags list
```

**3. Docker containers not starting:**
```bash
docker compose logs <service-name>
docker compose restart <service-name>

# Check container status
docker compose ps
```

**4. Airflow webserver network issue:**
```bash
# If webserver can't connect to airflow-db
docker compose stop airflow-webserver
docker compose rm -f airflow-webserver
docker compose up -d airflow-webserver
```

**5. Spark processor failing:**
```bash
docker logs spark-processor -f
```

**6. Database connection issues:**
```bash
docker exec postgres pg_isready -U user -d tiktok_safety_db
```

**7. Reset everything:**
```bash
cd streaming
docker compose down -v
rm -rf state/
./start_all.sh
```

**8. Startup timeout - Services not ready:**
```bash
# The start_all.sh script waits 85s for services
# If you see timeout warnings, wait additional 30-60s
# then check: http://localhost:8089 (Airflow)
```

---

## üõ†Ô∏è Tech Stack

### Core Technologies

| Category | Technology | Version |
|----------|------------|---------|
| **Language** | Python | 3.9+ |
| **Container** | Docker & Docker Compose | 20.10+ |
| **Stream Processing** | Apache Spark | 3.5.0 |
| **Message Queue** | Apache Kafka | 7.5.0 |
| **Object Storage** | MinIO | Latest |
| **Database** | PostgreSQL | 15 |
| **Orchestration** | Apache Airflow | 2.8.1 |
| **ML Tracking** | MLflow | 2.8.1 |
| **Dashboard** | Streamlit | 1.28+ |

### AI/ML Frameworks

| Framework | Purpose |
|-----------|---------|
| PyTorch | Deep learning backend |
| Transformers | Pre-trained models |
| CafeBERT | Vietnamese text classification |
| VideoMAE | Video frame analysis |

### Supporting Tools

| Tool | Purpose |
|------|---------|
| Selenium + Chrome | Web scraping |
| FFmpeg | Audio extraction |
| Decord | Video frame extraction |
| kafka-python | Kafka client |

---

## üë• Authors

<table>
  <tr>
    <td align="center">
      <a href="https://github.com/KhoiBui16">
        <img src="https://github.com/KhoiBui16.png" width="100px;" alt="KhoiBui16"/><br />
        <sub><b>KhoiBui16</b></sub>
      </a>
    </td>
    <td align="center">
      <a href="https://github.com/BinhAnndapoet">
        <img src="https://github.com/BinhAnndapoet.png" width="100px;" alt="BinhAnndapoet"/><br />
        <sub><b>BinhAnndapoet</b></sub>
      </a>
    </td>
    <td align="center">
      <a href="https://github.com/PhamQuocNam">
        <img src="https://github.com/PhamQuocNam.png" width="100px;" alt="PhamQuocNam"/><br />
        <sub><b>PhamQuocNam</b></sub>
      </a>
    </td>
  </tr>
</table>

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

**‚≠ê Star this repo if you find it helpful! ‚≠ê**

Made with ‚ù§Ô∏è by KhoiBui16, BinhAnndapoet & PhamQuocNam

</div>
