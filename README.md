# ğŸ›¡ï¸ TikTok Safety Platform - Big Data Harmful Content Detection System

<div align="center">

**ğŸ“š Course**: SE363 - Big Data Platform Application Development  
**ğŸ›ï¸ Institution**: University of Information Technology (UIT) - VNU-HCM  
**ğŸ‘¥ Authors**: [KhoiBui16](https://github.com/KhoiBui16) â€¢ [BinhAnndapoet](https://github.com/BinhAnndapoet) â€¢ [PhamQuocNam](https://github.com/PhamQuocNam)

---

![TikTok Safety](https://img.shields.io/badge/TikTok-Safety-ff0050?style=for-the-badge&logo=tiktok&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Apache Spark](https://img.shields.io/badge/Apache-Spark-E25A1C?style=for-the-badge&logo=apachespark&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/Apache-Kafka-231F20?style=for-the-badge&logo=apachekafka&logoColor=white)

**A Big Data platform for detecting harmful content on TikTok using multimodal AI (Text + Video + Fusion)**

</div>

---

## ğŸ“‹ Project Overview

This project implements a **Lambda Architecture** based Big Data platform for real-time detection of harmful content on TikTok videos. The system combines:

- **Batch Processing**: Training multimodal AI models (Text, Video, Fusion)
- **Stream Processing**: Real-time video analysis using Apache Spark Streaming
- **Serving Layer**: Streamlit Dashboard for monitoring and content moderation

### Key Capabilities

- ğŸ” **Multimodal Analysis**: Combines text (captions, comments) and video frame analysis
- âš¡ **Real-time Processing**: Stream processing with Kafka + Spark
- ğŸ¤– **AI-Powered Detection**: State-of-the-art models for content classification
- ğŸ“Š **Interactive Dashboard**: Real-time monitoring and content audit tools
- ğŸ”„ **MLflow Integration**: Model versioning and auto-update capabilities

---

## ğŸ“‘ Table of Contents

1. [Quick Start](#-quick-start)
2. [Project Structure](#-project-structure)
3. [Architecture](#ï¸-architecture)
4. [Layer Architecture](#-layer-architecture)
5. [Airflow DAGs](#-airflow-dags)
6. [Data Flow](#-data-flow)
7. [Features](#-features)
8. [AI Models](#-ai-models)
9. [Installation Guide](#-installation-guide)
10. [Usage](#-usage)
11. [Testing](#-testing)
12. [Documentation](#-documentation)
13. [Troubleshooting](#-troubleshooting)
14. [Tech Stack](#ï¸-tech-stack)
15. [Authors](#-authors)

---

## ğŸš€ Quick Start

### Clone Repository

```bash
git clone https://github.com/BinhAnndapoet/UIT-SE363-Big-Data-Platform-Application-Development.git
cd UIT-SE363-Big-Data-Platform-Application-Development
```

### Setup Environment

```bash
# Copy environment file
cp streaming/.env.example streaming/.env

# (Optional) Edit .env if needed
nano streaming/.env
```

### Run with Docker (Ubuntu)

```bash
cd streaming
chmod +x start_all.sh
./start_all.sh
```

### Access Services

| Service | URL | Credentials |
|---------|-----|-------------|
| **Dashboard** | http://localhost:8501 | - |
| **Airflow** | http://localhost:8080 | admin / admin |
| **MinIO Console** | http://localhost:9001 | admin / password123 |
| **Spark Master** | http://localhost:9090 | - |
| **MLflow** | http://localhost:5000 | - |

---

## ğŸ“ Project Structure

```
UIT-SE363-Big-Data-Platform-Application-Development/
â”‚
â”œâ”€â”€ streaming/                          # ğŸ”„ Streaming Pipeline
â”‚   â”œâ”€â”€ airflow/                        # Airflow configuration
â”‚   â”‚   â””â”€â”€ dags/                       # DAG definitions
â”‚   â”‚       â”œâ”€â”€ 1_TIKTOK_ETL_COLLECTOR.py
â”‚   â”‚       â””â”€â”€ 2_TIKTOK_STREAMING_PIPELINE.py
â”‚   â”œâ”€â”€ dashboard/                      # Streamlit Dashboard
â”‚   â”‚   â”œâ”€â”€ app.py                      # Main entry point
â”‚   â”‚   â””â”€â”€ page_modules/               # Page components
â”‚   â”‚       â”œâ”€â”€ dashboard_monitor.py
â”‚   â”‚       â”œâ”€â”€ system_operations.py
â”‚   â”‚       â”œâ”€â”€ content_audit.py
â”‚   â”‚       â”œâ”€â”€ database_manager.py
â”‚   â”‚       â””â”€â”€ project_info.py
â”‚   â”œâ”€â”€ ingestion/                      # Data Ingestion Layer
â”‚   â”‚   â”œâ”€â”€ crawler.py                  # TikTok crawler (Selenium)
â”‚   â”‚   â”œâ”€â”€ downloader.py               # Video downloader
â”‚   â”‚   â”œâ”€â”€ main_worker.py              # Main ingestion worker
â”‚   â”‚   â””â”€â”€ clients/                    # External clients
â”‚   â”‚       â”œâ”€â”€ minio_client.py
â”‚   â”‚       â””â”€â”€ kafka_client.py
â”‚   â”œâ”€â”€ processing/                     # Stream Processing
â”‚   â”‚   â””â”€â”€ spark_processor.py          # Spark AI inference
â”‚   â”œâ”€â”€ mlflow/                         # MLflow Integration
â”‚   â”‚   â”œâ”€â”€ client.py                   # Model registry client
â”‚   â”‚   â””â”€â”€ model_updater.py            # Auto-update mechanism
â”‚   â”œâ”€â”€ spark/                          # Spark Docker config
â”‚   â”œâ”€â”€ scripts/                        # Automation scripts
â”‚   â”œâ”€â”€ tests/                          # Test files
â”‚   â”‚   â”œâ”€â”€ test_layer1_infrastructure.sh
â”‚   â”‚   â”œâ”€â”€ test_layer2_ingestion.sh
â”‚   â”‚   â”œâ”€â”€ test_layer3_processing.sh
â”‚   â”‚   â”œâ”€â”€ test_layer4_dashboard.sh
â”‚   â”‚   â””â”€â”€ run_all_tests.sh
â”‚   â”œâ”€â”€ docker-compose.yml              # Main compose file
â”‚   â”œâ”€â”€ start_all.sh                    # Full startup script
â”‚   â”œâ”€â”€ .env.example                    # Environment template
â”‚   â””â”€â”€ .env                            # Environment config (gitignored)
â”‚
â”œâ”€â”€ train_eval_module/                  # ğŸ¤– Model Training
â”‚   â”œâ”€â”€ text/                           # Text classification
â”‚   â”‚   â”œâ”€â”€ train_text_spark.py
â”‚   â”‚   â””â”€â”€ output/uitnlp_CafeBERT/
â”‚   â”œâ”€â”€ video/                          # Video classification
â”‚   â”‚   â”œâ”€â”€ train_video.py
â”‚   â”‚   â””â”€â”€ output/MCG-NJU_videomae-base-finetuned-kinetics/
â”‚   â”œâ”€â”€ fusion/                         # Multimodal fusion
â”‚   â”‚   â”œâ”€â”€ train_fusion.py
â”‚   â”‚   â””â”€â”€ output/fusion_videomae/
â”‚   â”œâ”€â”€ audio/                          # Audio (experimental)
â”‚   â”œâ”€â”€ scripts/                        # Utility scripts
â”‚   â”‚   â””â”€â”€ push_hf_model.py            # Push to HuggingFace Hub
â”‚   â””â”€â”€ shared_utils/                   # Common utilities
â”‚
â”œâ”€â”€ notebooks/                          # ğŸ““ Jupyter Notebooks
â”‚   â”œâ”€â”€ ScrapingVideoTiktok.ipynb       # Web scraping notebook
â”‚   â”œâ”€â”€ create_sub_samples_tiktok_links.ipynb
â”‚   â”œâ”€â”€ eda.ipynb                       # Exploratory Data Analysis
â”‚   â””â”€â”€ audio_trial.ipynb               # Audio experiments
â”‚
â”œâ”€â”€ docs/                               # ğŸ“– Documentation
â”‚   â”œâ”€â”€ streaming/                      # Streaming docs
â”‚   â”‚   â”œâ”€â”€ 01_PROJECT_OVERVIEW.md
â”‚   â”‚   â”œâ”€â”€ 02_LAYER_ARCHITECTURE.md
â”‚   â”‚   â”œâ”€â”€ 03_DASHBOARD_PAGES.md
â”‚   â”‚   â”œâ”€â”€ 04_SETUP_GUIDE.md
â”‚   â”‚   â”œâ”€â”€ 05_TESTING_GUIDE.md
â”‚   â”‚   â””â”€â”€ 06_API_REFERENCE.md
â”‚   â””â”€â”€ mlflow/                         # MLflow docs
â”‚       â””â”€â”€ MLFLOW_INTEGRATION_GUIDE.md
â”‚
â”œâ”€â”€ processed_data/                     # ğŸ“Š Processed Data
â”‚   â”œâ”€â”€ text/                           # Text CSV files
â”‚   â””â”€â”€ fusion/                         # Fusion training data
â”‚
â””â”€â”€ data/                               # ğŸ“¦ Raw Data
```

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        LAMBDA ARCHITECTURE                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   TikTok     â”‚â”€â”€â”€â–¶â”‚   Crawler    â”‚â”€â”€â”€â–¶â”‚   MinIO (Storage)    â”‚   â”‚
â”‚  â”‚   Videos     â”‚    â”‚   Service    â”‚    â”‚   Videos & Audios    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â”‚                        â”‚               â”‚
â”‚                             â–¼                        â–¼               â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                      â”‚    Kafka     â”‚â”€â”€â”€â–¶â”‚   Spark Streaming    â”‚   â”‚
â”‚                      â”‚   Broker     â”‚    â”‚   (AI Inference)     â”‚   â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                      â”‚               â”‚
â”‚                                                      â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Streamlit  â”‚â—€â”€â”€â”€â”‚  PostgreSQL  â”‚â—€â”€â”€â”€â”‚   Processed Results  â”‚   â”‚
â”‚  â”‚   Dashboard  â”‚    â”‚   Database   â”‚    â”‚                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Docker Services

| Service | Port | Description |
|---------|------|-------------|
| **Dashboard** | `8501` | Streamlit monitoring UI |
| **Airflow** | `8080` | DAG scheduling & orchestration |
| **Spark Master** | `9090` | Spark cluster management |
| **Spark Processor** | - | AI inference streaming job |
| **Kafka** | `9092` | Message broker |
| **MinIO** | `9000`, `9001` | Object storage (videos/audios) |
| **PostgreSQL** | `5432` | Results database |
| **MLflow** | `5000` | Model registry & tracking |

---

## ğŸ—ï¸ Layer Architecture

The system follows an **8-layer architecture**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 8: PRESENTATION          â”‚  Streamlit Dashboard (port 8501)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 7: DATA STORAGE          â”‚  PostgreSQL (processed_results)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 6: ORCHESTRATION         â”‚  Airflow DAGs (port 8080)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 5: STREAM PROCESSING     â”‚  Spark Streaming + AI Models        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 4: DATA INGESTION        â”‚  Crawler â†’ Downloader â†’ Producer    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 3: OBJECT STORAGE        â”‚  MinIO (videos, audios)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 2: MESSAGE QUEUE         â”‚  Kafka + Zookeeper                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Layer 1: INFRASTRUCTURE        â”‚  Docker Network, Volumes            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Layer Details

| Layer | Components | Key Files |
|-------|------------|-----------|
| **L1: Infrastructure** | Docker Network, Volumes | [docker-compose.yml](streaming/docker-compose.yml) |
| **L2: Message Queue** | Kafka (9092), Zookeeper | [docker-compose.yml](streaming/docker-compose.yml) |
| **L3: Object Storage** | MinIO (9000/9001) | [minio_client.py](streaming/ingestion/clients/minio_client.py) |
| **L4: Data Ingestion** | Crawler, Downloader, Producer | [crawler.py](streaming/ingestion/crawler.py), [main_worker.py](streaming/ingestion/main_worker.py) |
| **L5: Stream Processing** | Spark + AI Models | [spark_processor.py](streaming/processing/spark_processor.py) |
| **L6: Orchestration** | Airflow DAGs | [airflow/dags/](streaming/airflow/dags/) |
| **L7: Data Storage** | PostgreSQL | [db_migrator.py](streaming/db_migrator.py) |
| **L8: Presentation** | Streamlit Dashboard | [dashboard/app.py](streaming/dashboard/app.py) |

---

## ğŸ”„ Airflow DAGs

### DAG 1: `1_TIKTOK_ETL_COLLECTOR`

**Purpose**: Crawl TikTok videos by hashtags

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ monitor_db_health   â”‚ â”€â”€â”€â–º â”‚   crawl_tiktok_links   â”‚
â”‚ (pg_isready check)  â”‚      â”‚  (Selenium + Xvfb)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Task | Description | Timeout |
|------|-------------|---------|
| `monitor_db_health` | Check PostgreSQL connection | - |
| `crawl_tiktok_links` | Crawl TikTok with Selenium (headless) | 45 min |

### DAG 2: `2_TIKTOK_STREAMING_PIPELINE`

**Purpose**: Download videos, run AI inference, continuous processing loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ prepare_environ  â”‚â”€â”€â–ºâ”‚ check_kafka_infraâ”‚â”€â”€â–ºâ”‚ run_ingestion_workerâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ verify_spark_resultâ”‚â”€â”€â–ºâ”‚ wait_30s_cooldownâ”‚â”€â”€â–ºâ”‚ loop_self_triggerâ”‚
â”‚   (SQL Sensor)     â”‚   â”‚                 â”‚   â”‚  (Auto-restart)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Task | Description |
|------|-------------|
| `prepare_environment` | Check queue file exists |
| `check_kafka_infra` | Verify Kafka is healthy |
| `run_ingestion_worker` | Download â†’ Upload MinIO â†’ Send Kafka |
| `verify_spark_ai_result` | Wait for Spark processing |
| `wait_30s_cooldown` | Cooldown before next loop |
| `loop_self_trigger` | Self-trigger for continuous processing |

---

## ğŸ“Š Data Flow

```
     TikTok Website
          â”‚
          â–¼ (1. Crawl)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Crawler   â”‚ â”€â”€â”€â–º tiktok_links_viet.csv
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼ (2. Download)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Downloader â”‚â”€â”€â”€â”€â–ºâ”‚  MinIO  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼ (3. Produce)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Producer  â”‚â”€â”€â”€â”€â–ºâ”‚  Kafka  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼ (4. AI Inference)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         Spark Processor         â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚ Text â”‚ â”‚Video â”‚ â”‚Fusionâ”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼ (5. Store)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  PostgreSQL â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼ (6. Display)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Dashboard  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Features

### 1. Analytics Dashboard
- **KPI Monitoring**: Total processed videos, harmful detection rate, average risk score
- **Visual Analysis**: Time-series charts and category distribution
- **Real-time Updates**: Live data refresh from PostgreSQL

### 2. System Operations
- **Pipeline Control**: Start/Stop crawler and streaming pipelines
- **Status Monitor**: Real-time container and service health checks
- **System Logs**: Centralized logging viewer

### 3. Content Audit
- **Gallery Mode**: Visual grid of processed videos with risk scores
- **Detail View**: In-depth analysis of individual videos
- **Table View**: Sortable/filterable data table

### 4. Database Manager
- **Table Browser**: Schema inspection and data preview
- **Query Tool**: Execute custom SQL queries
- **Statistics**: Database performance metrics

### 5. Project Info
- **Architecture Diagrams**: Visual system documentation
- **Data Pipeline Flow**: End-to-end data journey
- **AI Models Documentation**: Model specifications

---

## ğŸ¤– AI Models

All models are available on HuggingFace Hub:

### Text Classification Model
**Repository**: [KhoiBui/tiktok-text-safety-classifier](https://huggingface.co/KhoiBui/tiktok-text-safety-classifier)

- **Base Model**: CafeBERT (uitnlp/CafeBERT)
- **Task**: Binary classification (safe/harmful)
- **Languages**: Vietnamese, English

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained("KhoiBui/tiktok-text-safety-classifier")
model = AutoModelForSequenceClassification.from_pretrained("KhoiBui/tiktok-text-safety-classifier")
```

### Video Classification Model
**Repository**: [KhoiBui/tiktok-video-safety-classifier](https://huggingface.co/KhoiBui/tiktok-video-safety-classifier)

- **Base Model**: VideoMAE (MCG-NJU/videomae-base-finetuned-kinetics)
- **Task**: Binary classification (safe/harmful)
- **Input**: 16 video frames (224x224)

### Multimodal Fusion Model
**Repository**: [KhoiBui/tiktok-multimodal-fusion-classifier](https://huggingface.co/KhoiBui/tiktok-multimodal-fusion-classifier)

- **Architecture**: Late Fusion with Cross-Attention
- **Text Backbone**: XLM-RoBERTa-base
- **Video Backbone**: VideoMAE-base

---

## ğŸ“¦ Installation Guide

### Prerequisites

- **OS**: Ubuntu 20.04+ or Windows 10+ with WSL2
- **Docker**: Docker Engine 20.10+ & Docker Compose v2
- **Python**: 3.9+
- **RAM**: Minimum 16GB (32GB recommended)

### Step 1: Clone Repository

```bash
git clone https://github.com/BinhAnndapoet/UIT-SE363-Big-Data-Platform-Application-Development.git
cd UIT-SE363-Big-Data-Platform-Application-Development
```

### Step 2: Setup Environment

```bash
# Copy environment template
cp streaming/.env.example streaming/.env

# (Optional) Create Python virtual environment
python3 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .\.venv\Scripts\Activate.ps1  # Windows

# Install dependencies
pip install -r requirements.txt
```

### Step 3: Run Docker

```bash
cd streaming
chmod +x start_all.sh
./start_all.sh
```

---

## ğŸš€ Usage

### Running the Pipeline

1. **Open Airflow** at http://localhost:8080

2. **Trigger DAG 1**: `1_TIKTOK_ETL_COLLECTOR`
   - Crawls TikTok videos by hashtags
   - Wait for completion (Success status)

3. **Trigger DAG 2**: `2_TIKTOK_STREAMING_PIPELINE`
   - Downloads videos to MinIO
   - Runs AI inference with Spark
   - Stores results in PostgreSQL
   - Auto-loops for continuous processing

4. **Monitor Dashboard** at http://localhost:8501

### Manual Docker Commands

```bash
cd streaming

# Start all services
docker compose up -d --build

# Check status
docker compose ps

# View logs
docker compose logs -f spark-processor

# Stop all services
docker compose down
```

---

## ğŸ§ª Testing

### Shell Scripts (Ubuntu)

```bash
cd streaming

# Run all tests
./tests/run_all_tests.sh

# Test individual layers
./tests/test_layer1_infrastructure.sh
./tests/test_layer2_ingestion.sh
./tests/test_layer3_processing.sh
./tests/test_layer4_dashboard.sh
```

### Python Tests

```bash
cd streaming
pytest tests/ -v
```

---

## ğŸ“– Documentation

| Document | Description |
|----------|-------------|
| [01_PROJECT_OVERVIEW.md](docs/streaming/01_PROJECT_OVERVIEW.md) | Project introduction |
| [02_LAYER_ARCHITECTURE.md](docs/streaming/02_LAYER_ARCHITECTURE.md) | Architecture details |
| [03_DASHBOARD_PAGES.md](docs/streaming/03_DASHBOARD_PAGES.md) | Dashboard usage guide |
| [04_SETUP_GUIDE.md](docs/streaming/04_SETUP_GUIDE.md) | Installation guide |
| [05_TESTING_GUIDE.md](docs/streaming/05_TESTING_GUIDE.md) | Testing documentation |
| [MLFLOW_INTEGRATION_GUIDE.md](docs/mlflow/MLFLOW_INTEGRATION_GUIDE.md) | MLflow setup |

---

## ğŸ”§ Troubleshooting

### Common Issues

**1. Docker containers not starting:**
```bash
docker compose logs <service-name>
docker compose restart <service-name>
```

**2. Spark processor failing:**
```bash
docker logs spark-processor -f
```

**3. Database connection issues:**
```bash
docker exec postgres pg_isready -U user -d tiktok_safety_db
```

**4. Reset everything:**
```bash
cd streaming
docker compose down -v
rm -rf state/
./start_all.sh
```

---

## ğŸ› ï¸ Tech Stack

### Core Technologies

| Category | Technology | Version |
|----------|------------|---------|
| **Language** | Python | 3.9+ |
| **Container** | Docker & Docker Compose | 20.10+ |
| **Stream Processing** | Apache Spark | 3.5.0 |
| **Message Queue** | Apache Kafka | 7.5.0 |
| **Object Storage** | MinIO | Latest |
| **Database** | PostgreSQL | 15 |
| **Orchestration** | Apache Airflow | 2.8.1 |
| **ML Tracking** | MLflow | 2.8.1 |
| **Dashboard** | Streamlit | 1.28+ |

### AI/ML Frameworks

| Framework | Purpose |
|-----------|---------|
| PyTorch | Deep learning backend |
| Transformers | Pre-trained models |
| CafeBERT | Vietnamese text classification |
| VideoMAE | Video frame analysis |

### Supporting Tools

| Tool | Purpose |
|------|---------|
| Selenium + Chrome | Web scraping |
| FFmpeg | Audio extraction |
| Decord | Video frame extraction |
| kafka-python | Kafka client |

---

## ğŸ‘¥ Authors

<table>
  <tr>
    <td align="center">
      <a href="https://github.com/KhoiBui16">
        <img src="https://github.com/KhoiBui16.png" width="100px;" alt="KhoiBui16"/><br />
        <sub><b>KhoiBui16</b></sub>
      </a>
    </td>
    <td align="center">
      <a href="https://github.com/BinhAnndapoet">
        <img src="https://github.com/BinhAnndapoet.png" width="100px;" alt="BinhAnndapoet"/><br />
        <sub><b>BinhAnndapoet</b></sub>
      </a>
    </td>
    <td align="center">
      <a href="https://github.com/PhamQuocNam">
        <img src="https://github.com/PhamQuocNam.png" width="100px;" alt="PhamQuocNam"/><br />
        <sub><b>PhamQuocNam</b></sub>
      </a>
    </td>
  </tr>
</table>

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

**â­ Star this repo if you find it helpful! â­**

Made with â¤ï¸ by KhoiBui16, BinhAnndapoet & PhamQuocNam

</div>
