"""
Project Info Page - Architecture & Pipeline Documentation
"""

import streamlit as st
from helpers import render_header
from config import EXTERNAL_URLS


def render_project_info():
    """Render the project information page"""
    render_header(
        title="Project Info",
        subtitle="Kiáº¿n trÃºc há»‡ thá»‘ng vÃ  tÃ i liá»‡u ká»¹ thuáº­t Big Data Pipeline.",
        icon="ğŸ“š",
    )

    tab1, tab2, tab3, tab4 = st.tabs(
        ["ğŸ—ï¸ Architecture", "ğŸ“Š Data Pipeline", "ğŸ¤– AI Models", "ğŸ“– Documentation"]
    )

    with tab1:
        _render_architecture()

    with tab2:
        _render_data_pipeline()

    with tab3:
        _render_ai_models()

    with tab4:
        _render_documentation()


def _render_architecture():
    """Render system architecture diagram"""
    st.subheader("ğŸ—ï¸ Kiáº¿n trÃºc Há»‡ thá»‘ng")

    st.markdown(
        """
    ### High-Level Architecture
    
    Há»‡ thá»‘ng **TikTok Harmful Content Detection** Ä‘Æ°á»£c xÃ¢y dá»±ng theo kiáº¿n trÃºc **Lambda Architecture** 
    káº¿t há»£p **Batch Processing** vÃ  **Stream Processing**.
    """
    )

    # Architecture Diagram using Mermaid
    st.markdown(
        """
    ```mermaid
    graph TB
        subgraph "ğŸ“¥ Data Ingestion"
            A[TikTok Web] --> B[Crawler Service]
            B --> C[MinIO Storage]
        end
        
        subgraph "ğŸ“¡ Message Queue"
            C --> D[Kafka Producer]
            D --> E[Kafka Broker]
        end
        
        subgraph "âš¡ Stream Processing"
            E --> F[Spark Streaming]
            F --> G[AI Models]
        end
        
        subgraph "ğŸ¤– AI Pipeline"
            G --> H[CafeBERT - Text]
            G --> I[VideoMAE - Video]
            H --> K[Late Fusion + Attention]
            I --> K
        end
        
        subgraph "ğŸ’¾ Data Storage"
            K --> L[PostgreSQL]
            L --> M[Streamlit Dashboard]
        end
        
        subgraph "ğŸ”§ Orchestration"
            N[Airflow] --> B
            N --> F
        end
    ```
    """
    )

    st.info("ğŸ“Œ Diagram trÃªn mÃ´ táº£ luá»“ng dá»¯ liá»‡u tá»« TikTok â†’ AI Analysis â†’ Dashboard")

    # Component Details
    st.markdown("---")
    st.markdown("### ğŸ§© Chi tiáº¿t cÃ¡c Components")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown(
            """
        #### ğŸ“¥ Data Ingestion Layer
        | Component | Technology | Purpose |
        |-----------|------------|---------|
        | Crawler | SeleniumWire + TikTok API | Intercept API JSON, láº¥y link+caption |
        | Downloader | yt-dlp (Mobile emulation) | Táº£i video tá»« TikTok |
        | Audio Extract | FFmpeg | TrÃ­ch xuáº¥t audio WAV (chÆ°a dÃ¹ng AI) |
        | Storage | MinIO (S3-compatible) | LÆ°u trá»¯ video/audio |
        | Producer | kafka-python | Gá»­i message vÃ o Kafka |
        
        #### ğŸ“¡ Message Queue Layer
        | Component | Technology | Purpose |
        |-----------|------------|---------|
        | Broker | Apache Kafka | Message streaming |
        | Zookeeper | Apache Zookeeper | Cluster coordination |
        """
        )

    with col2:
        st.markdown(
            """
        #### âš¡ Processing Layer
        | Component | Technology | Purpose |
        |-----------|------------|---------|
        | Streaming | Apache Spark 3.5 | Real-time micro-batch processing |
        | AI Fusion | PyTorch + Transformers | Multi-modal classification |
        
        #### ğŸ’¾ Storage Layer
        | Component | Technology | Purpose |
        |-----------|------------|---------|
        | Database | PostgreSQL 16 | Structured results |
        | Object Store | MinIO | Video/Audio files |
        | Model Registry | MLflow (optional) | Model versioning |
        """
        )


def _render_data_pipeline():
    """Render data pipeline documentation"""
    st.subheader("ğŸ“Š Data Pipeline Flow")

    st.markdown(
        """
    ### Pipeline Stages
    
    Dá»¯ liá»‡u Ä‘i qua **5 giai Ä‘oáº¡n chÃ­nh** tá»« thu tháº­p Ä‘áº¿n hiá»ƒn thá»‹ káº¿t quáº£:
    """
    )

    # Stage 1
    with st.expander(
        "**1ï¸âƒ£ Stage 1: Data Collection (Crawler + Downloader)**", expanded=True
    ):
        st.markdown(
            """
        ```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    CRAWLER + DOWNLOADER                       â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚  Step 1: SeleniumWire intercept TikTok API JSON               â”‚
        â”‚  Step 2: Extract video_id, author, caption tá»« API            â”‚
        â”‚  Step 3: yt-dlp táº£i video (Mobile iPhone emulation)          â”‚
        â”‚  Step 4: FFmpeg trÃ­ch xuáº¥t audio (.wav)                       â”‚
        â”‚  Step 5: Upload lÃªn MinIO (video + audio buckets)            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        ```
        
        **Files chÃ­nh:**
        - `ingestion/crawler.py` - SeleniumWire + API intercept
        - `ingestion/downloader.py` - yt-dlp mobile emulation
        - `ingestion/main_worker.py` - Pipeline orchestrator
        - `ingestion/audio_processor.py` - FFmpeg audio extraction
        
        **MinIO structure:**
        ```
        tiktok-raw-videos/            tiktok-raw-audios/
        â”œâ”€â”€ raw/harmful/              â”œâ”€â”€ raw/harmful/
        â”‚   â””â”€â”€ {video_id}.mp4        â”‚   â””â”€â”€ {video_id}.wav
        â””â”€â”€ raw/safe/                 â””â”€â”€ raw/safe/
            â””â”€â”€ {video_id}.mp4            â””â”€â”€ {video_id}.wav
        ```
        """
        )

    # Stage 2
    with st.expander("**2ï¸âƒ£ Stage 2: Event Streaming (Kafka)**"):
        st.markdown(
            """
        ```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    KAFKA PIPELINE                           â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚  Topic:    tiktok_raw_data                                   â”‚
        â”‚  Producer: main_worker.py (sau khi upload MinIO)            â”‚
        â”‚  Consumer: Spark Structured Streaming                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        ```
        
        **Kafka Message Schema (thá»±c táº¿):**
        ```json
        {
            "video_id": "7123456789",
            "minio_video_path": "tiktok-raw-videos/raw/harmful/7123456789.mp4",
            "minio_audio_path": "tiktok-raw-audios/raw/harmful/7123456789.wav",
            "clean_text": "Caption Ä‘Ã£ Ä‘Æ°á»£c lÃ m sáº¡ch...",
            "csv_label": "harmful",
            "timestamp": 1705312200.123
        }
        ```
        """
        )

    # Stage 3
    with st.expander("**3ï¸âƒ£ Stage 3: Stream Processing (Spark)**"):
        st.markdown(
            """
        ```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  SPARK STRUCTURED STREAMING                  â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚  Input:    Kafka topic (tiktok_raw_data)                     â”‚
        â”‚  Process:  Micro-batch (maxOffsetsPerTrigger=5)             â”‚
        â”‚  Text:     Láº¥y tá»« clean_text (caption, KHÃ”NG dÃ¹ng Whisper)  â”‚
        â”‚  Video:    Download tá»« MinIO â†’ Extract 16 frames            â”‚
        â”‚  Audio:    ChÆ°a sá»­ dá»¥ng (dá»± phÃ²ng cho tÆ°Æ¡ng lai)            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        ```
        
        **Processing steps (thá»±c táº¿):**
        1. Nháº­n Kafka message (JSON)
        2. Parse: video_id, minio_video_path, clean_text, csv_label
        3. Download video tá»« MinIO (boto3)
        4. Decord: TrÃ­ch 16 frames tá»« video
        5. **Text Ä‘Ã£ cÃ³ sáºµn** (caption tá»« TikTok API, khÃ´ng cáº§n Whisper)
        6. Gá»­i song song Ä‘áº¿n AI models
        """
        )

    # Stage 4
    with st.expander("**4ï¸âƒ£ Stage 4: AI Analysis (Multi-Modal)**"):
        st.markdown(
            """
        ```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  AI PIPELINE (AUTO-FALLBACK)                 â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚  Step 1: Thá»­ load FUSION MODEL trÆ°á»›c                         â”‚
        â”‚    â€¢ Text: uitnlp/CafeBERT backbone                         â”‚
        â”‚    â€¢ Video: MCG-NJU/VideoMAE-base backbone                  â”‚
        â”‚    â€¢ Fusion: Cross-Attention + Gating (50-50 weights)       â”‚
        â”‚    â€¢ Output: Single fusion_score tá»« softmax [0-1]           â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚  Fallback: Náº¿u FUSION khÃ´ng load Ä‘Æ°á»£c â†’ LATE_SCORE          â”‚
        â”‚    â€¢ Cháº¡y 2 models riÃªng (text + video)                     â”‚
        â”‚    â€¢ avg_score = text_score * 0.3 + video_score * 0.7       â”‚
        â”‚    â€¢ Configurable via env: TEXT_WEIGHT (0 to 1)             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        ```
        
        **Logic trong spark_processor.py:**
        ```python
        # LuÃ´n thá»­ FUSION trÆ°á»›c
        model, tokenizer, processor = get_fusion_model()
        if model is None:
            # FUSION khÃ´ng load Ä‘Æ°á»£c â†’ Auto-fallback vá» LATE_SCORE
            actual_use_fusion = False
            log_to_db("âš ï¸ FUSION model not available, falling back to LATE_SCORE")
        else:
            actual_use_fusion = True
            log_to_db("âœ… FUSION model loaded successfully!")
        ```
        
        **FUSION mode (50-50 weights Ä‘Ã£ train):**
        ```python
        fusion_config = {
            "video_weight": 0.5,  # Äá»“ng bá»™ vá»›i train_eval_module
            "text_weight": 0.5,   # Äá»“ng bá»™ vá»›i train_eval_module  
            "fusion_type": "attention",
        }
        ```
        
        **LATE_SCORE mode (fallback vá»›i 30-70 default):**
        ```python
        TEXT_WEIGHT = float(os.getenv("TEXT_WEIGHT", "0.3"))  # Default 30%
        VIDEO_WEIGHT = 1.0 - TEXT_WEIGHT  # Default 70%
        avg_score = (text_score * TEXT_WEIGHT) + (video_score * VIDEO_WEIGHT)
        ```
        
        > **LÆ°u Ã½:** FUSION lÃ  mode chÃ­nh. LATE_SCORE chá»‰ Ä‘Æ°á»£c dÃ¹ng khi khÃ´ng load Ä‘Æ°á»£c FUSION model.
        > Audio Ä‘Ã£ Ä‘Æ°á»£c trÃ­ch xuáº¥t nhÆ°ng chÆ°a tÃ­ch há»£p vÃ o AI pipeline.
        """
        )

    # Stage 5
    with st.expander("**5ï¸âƒ£ Stage 5: Results Storage & Visualization**"):
        st.markdown(
            """
        ```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                  DATA SINK                                  â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚  Database:  PostgreSQL (processed_results table)            â”‚
        â”‚  Dashboard: Streamlit real-time visualization               â”‚
        â”‚  Alerts:    (Optional) Webhook notifications                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        ```
        
        **Database schema:**
        ```sql
        CREATE TABLE processed_results (
            video_id VARCHAR(50) PRIMARY KEY,
            raw_text TEXT,
            human_label VARCHAR(20),
            text_verdict VARCHAR(20),
            text_score DOUBLE PRECISION,
            video_verdict VARCHAR(20),
            video_score DOUBLE PRECISION,
            avg_score DOUBLE PRECISION,
            threshold DOUBLE PRECISION,
            final_decision VARCHAR(50),
            processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        ```
        """
        )


def _render_ai_models():
    """Render AI models documentation"""
    st.subheader("ğŸ¤– AI Models Documentation")

    st.markdown(
        """
    ### Multi-Modal Harmful Content Detection
    
    Há»‡ thá»‘ng sá»­ dá»¥ng **Fusion Model (Text + Video)** vá»›i attention mechanism Ä‘á»ƒ káº¿t há»£p káº¿t quáº£:
    """
    )

    # Model cards
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown(
            """
        <div style="
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            border-radius: 12px;
            min-height: 280px;
            overflow: visible;
        ">
            <h3 style="color: white; margin: 0 0 10px 0;">ğŸ“ Text Model</h3>
            <p style="color: #ddd; margin: 5px 0;"><b>Architecture:</b> CafeBERT (uitnlp)</p>
            <p style="color: #ddd; margin: 5px 0;"><b>Input:</b> Vietnamese text/caption</p>
            <p style="color: #ddd; margin: 5px 0;"><b>Output:</b> Harmful probability [0-1]</p>
            <p style="color: #ddd; margin: 5px 0;"><b>Features:</b> Rule-based + AI</p>
            <hr style="border-color: rgba(255,255,255,0.2); margin: 10px 0;">
            <p style="color: #aaa; font-size: 0.85em; line-height: 1.4;">
                PhÃ¢n tÃ­ch ngá»¯ nghÄ©a vÄƒn báº£n tiáº¿ng Viá»‡t, káº¿t há»£p blacklist keywords
                vá»›i deep learning Ä‘á»ƒ phÃ¡t hiá»‡n ná»™i dung Ä‘á»™c háº¡i.
            </p>
        </div>
        """,
            unsafe_allow_html=True,
        )

    with col2:
        st.markdown(
            """
        <div style="
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            padding: 20px;
            border-radius: 12px;
            min-height: 280px;
            overflow: visible;
        ">
            <h3 style="color: white; margin: 0 0 10px 0;">ğŸ¬ Video Model</h3>
            <p style="color: #ddd; margin: 5px 0;"><b>Architecture:</b> VideoMAE</p>
            <p style="color: #ddd; margin: 5px 0;"><b>Input:</b> 16 video frames</p>
            <p style="color: #ddd; margin: 5px 0;"><b>Output:</b> Harmful probability [0-1]</p>
            <p style="color: #ddd; margin: 5px 0;"><b>Base:</b> MCG-NJU/videomae-base</p>
            <hr style="border-color: rgba(255,255,255,0.2); margin: 10px 0;">
            <p style="color: #aaa; font-size: 0.85em; line-height: 1.4;">
                PhÃ¢n tÃ­ch chuá»—i video frames, sá»­ dá»¥ng masked autoencoder
                Ä‘á»ƒ phÃ¡t hiá»‡n ná»™i dung báº¡o lá»±c vÃ  khÃ´ng phÃ¹ há»£p.
            </p>
        </div>
        """,
            unsafe_allow_html=True,
        )

    with col3:
        st.markdown(
            """
        <div style="
            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
            padding: 20px;
            border-radius: 12px;
            min-height: 280px;
            overflow: visible;
        ">
            <h3 style="color: white; margin: 0 0 10px 0;">ğŸ”¥ Fusion Model</h3>
            <p style="color: #ddd; margin: 5px 0;"><b>Architecture:</b> Late Fusion + Attention</p>
            <p style="color: #ddd; margin: 5px 0;"><b>Input:</b> Text + Video features</p>
            <p style="color: #ddd; margin: 5px 0;"><b>Output:</b> Final harmful score</p>
            <p style="color: #ddd; margin: 5px 0;"><b>Threshold:</b> 0.5 (configurable)</p>
            <hr style="border-color: rgba(255,255,255,0.2); margin: 10px 0;">
            <p style="color: #aaa; font-size: 0.85em; line-height: 1.4;">
                Cross-attention fusion káº¿t há»£p text vÃ  video features
                vá»›i gating mechanism Ä‘á»ƒ quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng.
            </p>
        </div>
        """,
            unsafe_allow_html=True,
        )

    # Fusion explanation
    st.markdown("---")
    st.markdown("### ğŸ”— Late Fusion Strategy")

    st.markdown(
        """
    **CÃ¡ch Fusion Model hoáº¡t Ä‘á»™ng:**
    
    ```python
    class LateFusionModel:
        def forward(self, text_input, video_frames):
            # 1. Extract features from backbones
            text_feat = text_backbone(text_input)       # CafeBERT [CLS] token
            video_feat = video_backbone(video_frames)   # VideoMAE mean pooling
            
            # 2. Project to same dimension (256)
            t_proj = text_proj(text_feat)   # (B, 256)
            v_proj = video_proj(video_feat) # (B, 256)
            
            # 3. Cross-Attention Fusion
            t_attended = cross_attn_t2v(t_proj, v_proj, v_proj)
            v_attended = cross_attn_v2t(v_proj, t_proj, t_proj)
            
            # 4. Gating mechanism
            concat = torch.cat([t_attended, v_attended], dim=1)
            gate = sigmoid(gate_layer(concat))  # [0-1] weight
            combined = gate * t_attended + (1 - gate) * v_attended
            
            # 5. Classification
            logits = classifier(combined)  # [safe, harmful]
            return softmax(logits)[:, 1]   # harmful probability
    ```
    
    **Táº¡i sao chá»n Late Fusion vá»›i Attention?**
    - Cross-attention cho phÃ©p text vÃ  video "tham kháº£o" láº«n nhau
    - Gating mechanism tá»± Ä‘á»™ng há»c weight dá»±a trÃªn context
    - Hiá»‡u quáº£ hÆ¡n simple weighted average (40-40-20)
    """
    )


def _render_documentation():
    """Render project documentation"""
    st.subheader("ğŸ“– TÃ i liá»‡u Dá»± Ã¡n")

    st.markdown(
        """
    ### ğŸ“ Project Structure
    
    ```
    UIT-SE363-Big-Data-Platform-Application-Development/
    â”œâ”€â”€ ğŸ“‚ streaming/                     # Main application
    â”‚   â”œâ”€â”€ ğŸ“‚ ingestion/               # Data collection
    â”‚   â”‚   â”œâ”€â”€ crawler.py              # SeleniumWire + TikTok API
    â”‚   â”‚   â”œâ”€â”€ downloader.py           # yt-dlp video download
    â”‚   â”‚   â”œâ”€â”€ main_worker.py          # Pipeline orchestrator
    â”‚   â”‚   â””â”€â”€ audio_processor.py      # FFmpeg audio extraction
    â”‚   â”‚
    â”‚   â”œâ”€â”€ ğŸ“‚ processing/              # Spark + AI
    â”‚   â”‚   â””â”€â”€ spark_processor.py      # Streaming + Fusion AI
    â”‚   â”‚
    â”‚   â”œâ”€â”€ ğŸ“‚ dashboard/               # Streamlit UI
    â”‚   â”‚   â”œâ”€â”€ app.py                  # Entry point
    â”‚   â”‚   â”œâ”€â”€ helpers.py              # DB queries
    â”‚   â”‚   â””â”€â”€ page_modules/           # Tab pages
    â”‚   â”‚
    â”‚   â”œâ”€â”€ ğŸ“‚ airflow/                 # DAG orchestration
    â”‚   â”‚   â””â”€â”€ dags/                   # 3 DAGs
    â”‚   â”‚
    â”‚   â”œâ”€â”€ docker-compose.yml        # 12 services
    â”‚   â””â”€â”€ start_all.sh              # One-click start
    â”‚
    â”œâ”€â”€ ğŸ“‚ train_eval_module/          # Model training
    â”‚   â”œâ”€â”€ text/                      # CafeBERT, XLM-RoBERTa
    â”‚   â”œâ”€â”€ video/                     # VideoMAE
    â”‚   â””â”€â”€ fusion/                    # Late Fusion + Attention
    â”‚
    â””â”€â”€ ğŸ“‚ processed_data/             # Training datasets
    ```
    """
    )

    st.markdown("---")
    st.markdown("### ğŸš€ Quick Start Guide")

    st.code(
        """
# 1. Clone repository
git clone https://github.com/TrungPhamDac/UIT-SE363-BigData.git
cd UIT-SE363-Big-Data-Platform-Application-Development/streaming

# 2. Start all services (one-click)
./start_all.sh
# Hoáº·c: docker compose up -d --build

# 3. Äá»£i services khá»Ÿi Ä‘á»™ng (~2-3 phÃºt)
docker ps  # Kiá»ƒm tra status

# 4. Truy cáº­p Dashboard
open http://localhost:8501

# 5. Khá»Ÿi cháº¡y Pipeline
# Dashboard â†’ System Operations â†’ Trigger DAGs
# Hoáº·c: Airflow UI http://localhost:8080 (admin/admin)
    """,
        language="bash",
    )

    st.markdown("---")
    st.markdown("### ğŸ”— Useful Links")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.link_button(
            "ğŸ“Š Dashboard", EXTERNAL_URLS["dashboard"], use_container_width=True
        )
        st.link_button("ğŸŒ Airflow", EXTERNAL_URLS["airflow"], use_container_width=True)

    with col2:
        st.link_button(
            "ğŸ“¦ MinIO", EXTERNAL_URLS["minio_console"], use_container_width=True
        )
        st.link_button(
            "ğŸ“ˆ Spark UI", EXTERNAL_URLS["spark_ui"], use_container_width=True
        )

    with col3:
        st.link_button(
            "ğŸ“š GitHub",
            "https://github.com/BinhAnndapoet/UIT-SE363-Big-Data-Platform-Application-Development",
            use_container_width=True,
        )
        st.link_button(
            "ğŸ“– Docs",
            "https://github.com/BinhAnndapoet/UIT-SE363-Big-Data-Platform-Application-Development?tab=readme-ov-file#-documentation",
            use_container_width=True,
        )
